{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Corpus Processing\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>custom_comment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>1 Pricing and Fairness</th>\n",
       "      <th>2 Driver professionalism</th>\n",
       "      <th>3 Driver behaviour</th>\n",
       "      <th>4 Customer Service</th>\n",
       "      <th>5 Application</th>\n",
       "      <th>6 Lost things</th>\n",
       "      <th>7 Vehicle Condition</th>\n",
       "      <th>8 Safety &amp; reliability</th>\n",
       "      <th>9 General bad</th>\n",
       "      <th>10 Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>The driver didn’t pay back the rest of the money</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2247</td>\n",
       "      <td>He is the worst driver in Utaxi and I would de...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2272</td>\n",
       "      <td>A simple “hello” or response would be perfect....</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3229</td>\n",
       "      <td>Not so great service</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3576</td>\n",
       "      <td>Worst driver ever, he’s a racist was screaming...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                     custom_comment  sentiment  \\\n",
       "0     49   The driver didn’t pay back the rest of the money         -1   \n",
       "1   2247  He is the worst driver in Utaxi and I would de...         -1   \n",
       "2   2272  A simple “hello” or response would be perfect....         -1   \n",
       "3   3229                               Not so great service         -1   \n",
       "4   3576  Worst driver ever, he’s a racist was screaming...         -1   \n",
       "\n",
       "   1 Pricing and Fairness  2 Driver professionalism  3 Driver behaviour  \\\n",
       "0                       1                         0                   1   \n",
       "1                       0                         0                   1   \n",
       "2                       0                         0                   1   \n",
       "3                       0                         0                   0   \n",
       "4                       0                         0                   1   \n",
       "\n",
       "   4 Customer Service  5 Application  6 Lost things  7 Vehicle Condition  \\\n",
       "0                   0              0              0                    0   \n",
       "1                   0              0              0                    0   \n",
       "2                   0              0              0                    0   \n",
       "3                   0              0              0                    0   \n",
       "4                   0              0              0                    0   \n",
       "\n",
       "   8 Safety & reliability  9 General bad  10 Other  \n",
       "0                       0              0         0  \n",
       "1                       0              0         0  \n",
       "2                       0              0         0  \n",
       "3                       0              1         0  \n",
       "4                       0              0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "reviews = pd.read_csv(\"../datasets/annotated_data_topic_classification.csv\", encoding='utf-8')\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'an', 'am' 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n",
    "             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n",
    "             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n",
    "             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n",
    "             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']\n",
    "\n",
    "short_forms = {\n",
    "    \"don't\": \"do not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"must've\": \"must have\",\n",
    "    # Add more short forms and their full forms as needed\n",
    "}\n",
    "\n",
    "def make_lower(text):\n",
    "     return text.lower()\n",
    "     \n",
    "\n",
    "def replace_short_forms(text):\n",
    "    # Create a regular expression pattern to match short forms as standalone words\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(short_forms.keys()), re.IGNORECASE)\n",
    "    \n",
    "    # Replace short forms with their corresponding full forms using a lambda function\n",
    "    full_forms_text = re.sub(pattern, lambda match: short_forms[match.group(0)], text)\n",
    "    \n",
    "    return full_forms_text\n",
    "\n",
    "\n",
    "# (?) remove quotation marks, unnecessary punctuation, [{}[]\\/+*%|^%#@!?()]\n",
    "def punctuation_remover(text):\n",
    "    pattern = r'[{}\\[\\]\\\\\\/\\+\\*%\\|\\^%#@\\(\\)\\$\\?\\!\\\"]'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "\n",
    "def lemma_stopwords_token(text):\n",
    "      le=WordNetLemmatizer()\n",
    "      word_tokens=nltk.word_tokenize(text)\n",
    "      word_tokens =[token for token in word_tokens if token.isalpha()]\n",
    "      tokens=[le.lemmatize(token) for token in word_tokens if token not in stopwords and len(token)>2]\n",
    "      processed_text =\" \".join(tokens)\n",
    "      return processed_text\n",
    "\n",
    "\n",
    "# main preprocessing function\n",
    "def preprocessing(text):\n",
    "    reviews = make_lower(text)\n",
    "    reviews = replace_short_forms(reviews)\n",
    "    reviews = punctuation_remover(reviews)\n",
    "    reviews = lemma_stopwords_token(reviews)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take reviews from dataset and preprocess them + convert to list + numpy.ndarray\n",
    "data = [preprocessing(custom_comment) for custom_comment in reviews['custom_comment'].to_list()]\n",
    "data = np.array(data)\n",
    "\n",
    "topics = reviews.columns.values[3:].tolist()\n",
    "labels = reviews[topics].values\n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 Pricing and Fairness', '2 Driver professionalism', '3 Driver behaviour', '4 Customer Service', '5 Application', '6 Lost things', '7 Vehicle Condition', '8 Safety & reliability', '9 General bad', '10 Other']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(topics)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "# X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3808,), (952,), (3808, 10), (952, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "embedding_dim = 50   #hyperparameter representing the dimensionality of the embedding space, in NLP tasks often set to a value between 50 and 300\n",
    "                    #each word index in the vocabulary will be represented as a 50-dimensional vector in the embedding space\n",
    "sequence_length =  100 #Keeping a fixed length of all reviews to max 400 words\n",
    "max_vocab_len = 10000  # vocabulary size limits the number of unique tokens (words or subwords)\n",
    "                    # Setting an upper limit helps control the size of the model and prevents it from learning an excessively large vocabulary.\n",
    "batch_size = 64 #Number of samples to work through before updating the internal model parameters via back propagation. The higher the batch, the more memory you need.\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate text vectorization layer\n",
    "\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize='lower',\n",
    "    max_tokens=max_vocab_len - 1,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# fit the text vector to the training text\n",
    "vectorize_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a function to see the result of using this layer to preprocess some data.\n",
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label\n",
    "\n",
    "# Vectorize the data if not include in Model\n",
    "train_ds = train_dataset.map(vectorize_text)\n",
    "test_ds = test_dataset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text : \n",
      " advertising other service \n",
      "\n",
      " Vectorized format : \n",
      "[[18 13  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]] \n",
      "\n",
      " shape : (1, 100)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(X_train)\n",
    "print(f\"original text : \\n {random_sentence} \\n\\n Vectorized format : \\n{vectorize_layer([random_sentence])} \\n\\n shape : {vectorize_layer([random_sentence]).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 most common words : ['', '[UNK]', 'and', 'driver', 'not'] \n",
      " \n",
      " 5 least common words : ['abrupt', 'abroad', 'ability', 'abandoned', 'ab']\n"
     ]
    }
   ],
   "source": [
    "print(f\" 5 most common words : {vectorize_layer.get_vocabulary()[:5]} \\n \\n 5 least common words : {vectorize_layer.get_vocabulary()[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TOPIC_MODEL\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 100)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 50)           500050    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 64)           29440     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 543292 (2.07 MB)\n",
      "Trainable params: 543292 (2.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# lstm model with PreProcessing layer\n",
    "inputs = layers.Input(shape = (1,), dtype = 'string')\n",
    "x = vectorize_layer(inputs)\n",
    "x = layers.Embedding( \n",
    "    input_dim = max_vocab_len + 1, # int, the size of our vocabulary, maximum integer index + 1 \n",
    "    output_dim = embedding_dim, # int, dimensions to which each words shall be mapped\n",
    "    input_length = sequence_length, #Length of input sequences\n",
    "    mask_zero=True #to ignore padding\n",
    "    )(x)\n",
    "x = layers.LSTM(units=64, return_sequences=True)(x)\n",
    "x = layers.LSTM(units=32)(x)\n",
    "x = layers.Dense(units=32, activation = 'relu')(x)\n",
    "x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "predictions = layers.Dense(units=len(topics), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, predictions, name = 'TOPIC_MODEL')\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #1e-3 = 0.001\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    # metrics=[tf.keras.metrics.Accuracy(),\n",
    "    #          tf.keras.metrics.FalseNegatives(),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "60/60 [==============================] - 15s 99ms/step - loss: 0.5457 - accuracy: 0.2358\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 5s 80ms/step - loss: 0.3532 - accuracy: 0.2844\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 5s 87ms/step - loss: 0.3259 - accuracy: 0.3054\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 6s 96ms/step - loss: 0.3050 - accuracy: 0.3645\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 5s 80ms/step - loss: 0.2820 - accuracy: 0.4157\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 5s 88ms/step - loss: 0.2602 - accuracy: 0.5087\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 6s 98ms/step - loss: 0.2349 - accuracy: 0.6056\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 5s 81ms/step - loss: 0.2148 - accuracy: 0.6767\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 5s 86ms/step - loss: 0.1967 - accuracy: 0.7103\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 6s 98ms/step - loss: 0.1812 - accuracy: 0.7348\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(X_train, y_train, #train_dataset#Training data : features (review) and classes (positive or negative)\n",
    "                    batch_size=batch_size, #Number of samples to work through before updating the internal model parameters via back propagation. The higher the batch, the more memory you need.\n",
    "                    epochs=epochs,\n",
    "                    verbose=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 3s 26ms/step - loss: 0.1956 - accuracy: 0.6838\n",
      "Test loss: 0.19560971856117249, Test accuracy: 0.6838235259056091\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print ('Test loss: {0}, Test accuracy: {1}'.format(results[0],results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "[[0.4641065]]\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    WORK_DIR = 'D:/DEV2/Text-Classification-project/'\n",
    "    DATASET_SENTIMENT = WORK_DIR + '/datasets/annotated_data_sentiment.csv'\n",
    "    DATASET_TOPIC = WORK_DIR + '/datasets/annotated_data_topic_classification.csv'\n",
    "    SRC_PATH = WORK_DIR + '/src'\n",
    "    SENTIMENT_MODEL_PATH = WORK_DIR + '/models/sentiment_model'\n",
    "    TOPIC_MODEL_PATH = WORK_DIR + '/models/topic_model'\n",
    "\n",
    "    # constants\n",
    "    embedding_dim = 50\n",
    "    sequence_length = 100 \n",
    "    max_vocab_len = 10000\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    num_topics = 10\n",
    "    TOPICS = ['1 Pricing and Fairness', '2 Driver professionalism', '3 Driver behaviour', '4 Customer Service', '5 Application', '6 Lost things', '7 Vehicle Condition', '8 Safety & reliability', '9 General bad', '10 Other']\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicClassificationModelBuild:\n",
    "    def __init__(self, config):\n",
    "        self.max_vocab_len = config.max_vocab_len\n",
    "        self.embedding_dim = config.embedding_dim\n",
    "        self.sequence_length = config.sequence_length\n",
    "        self.batch_size = config.batch_size\n",
    "        self.epochs = config.epochs\n",
    "        self.num_topics = config.num_topics\n",
    "        self.work_dir = config.WORK_DIR\n",
    "        self.dataset_sentiment = config.DATASET_SENTIMENT\n",
    "        self.vectorize_layer = layers.TextVectorization(\n",
    "            max_tokens=config.max_vocab_len,\n",
    "            output_mode='int',\n",
    "            output_sequence_length=config.sequence_length\n",
    "        )\n",
    "\n",
    "    \n",
    "    def preprocess_data(self, dataset_path):\n",
    "        # read CSV into pandas dataframe\n",
    "        reviews = pd.read_csv(dataset_path, encoding='utf-8')\n",
    "\n",
    "        # preprocess text with methods defined in preprocessing.py\n",
    "        data = [preprocessing(custom_comment) for custom_comment in reviews['custom_comment'].to_list()]\n",
    "        data = np.array(data)\n",
    "\n",
    "        topics = reviews.columns.values[3:].tolist()\n",
    "        labels = reviews[topics].values\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "        self.vectorize_layer.adapt(X_train)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        # lstm model with PreProcessing layer\n",
    "        inputs = layers.Input(shape = (1,), dtype = 'string')\n",
    "        x = self.vectorize_layer(inputs)\n",
    "        x = layers.Embedding( \n",
    "            input_dim = self.max_vocab_len + 1, # int, the size of our vocabulary, maximum integer index + 1 \n",
    "            output_dim = self.embedding_dim, # int, dimensions to which each words shall be mapped\n",
    "            input_length = self.sequence_length, #Length of input sequences\n",
    "            mask_zero=True #to ignore padding\n",
    "            )(x)\n",
    "        x = layers.LSTM(units=64, return_sequences=True)(x)\n",
    "        x = layers.LSTM(units=32)(x)\n",
    "        x = layers.Dense(units=32, activation = 'relu')(x)\n",
    "        x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "        predictions = layers.Dense(units=self.num_topics, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, predictions, name = 'TOPIC_MODEL')\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #1e-3 = 0.001\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            # metrics=[tf.keras.metrics.Accuracy(),\n",
    "            #          tf.keras.metrics.FalseNegatives(),\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def train_model(self, model, X_train, y_train, X_test, y_test, verbose=1):\n",
    "        try:\n",
    "            history = model.fit(X_train, y_train, \n",
    "                                batch_size=self.batch_size,\n",
    "                                epochs=self.epochs,\n",
    "                                verbose=verbose)\n",
    "            \n",
    "            results = model.evaluate(X_test, y_test)\n",
    "            print ('Test loss: {0}, Test accuracy: {1}'.format(results[0],results[1]))\n",
    "\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during model training: {e}\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "    \n",
    "    def run_training(self, dataset_path):\n",
    "        # Preprocess data\n",
    "        X_train, X_test, y_train, y_test = self.preprocess_data(dataset_path)\n",
    "\n",
    "        # Build a model\n",
    "        model = self.build_model()\n",
    "\n",
    "        # Train LSTM model\n",
    "        history = self.train_lstm_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        # Return relevant information or results\n",
    "        return {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'lstm_model': model,\n",
    "            'training_history': history\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = TopicClassificationModelBuild(config=Config)\n",
    "\n",
    "# Run the entire pipeline\n",
    "model.run_training(dataset_path = Config.DATASET_TOPIC)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save, load, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/DEV2/Text-Classification-project//models/topic_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/DEV2/Text-Classification-project//models/topic_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(Config.TOPIC_MODEL_PATH, 'topic_model', save_format='tf')\n",
    "# lstm_model.save('lstm_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TOPIC_MODEL\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 100)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 50)           500050    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 64)           29440     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 543292 (2.07 MB)\n",
      "Trainable params: 543292 (2.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_topic_model = tf.keras.models.load_model(Config.TOPIC_MODEL_PATH)\n",
    "\n",
    "# Show the model architecture\n",
    "new_topic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['driver started idle']\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[9.9873811e-01 2.6529160e-06 6.9647026e-04 6.7480443e-07 2.9194103e-07\n",
      "  2.7279872e-09 4.1279651e-17 8.4031821e-19 6.7310134e-06 1.6558518e-09]]\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"The driver started idle\",\n",
    "    # \"driver is a cheat\",\n",
    "    # \"The drivers behaviour is inappropriate\",\n",
    "    # \"I had a couple of rides with your service before and they were nice, but this time there wasn't a seatbelt which I believe is totally not OK. and the driver just said Are yoou going or not??\",\n",
    "    # \"I lost my laptop!\",\n",
    "    # \"driver is a cheat. I lost my laptop!\",\n",
    "    # \"bad\",\n",
    "    # \"your customer service never replies\",\n",
    "    # \"bad smell\",\n",
    "    # \"want refund\",\n",
    "]\n",
    "\n",
    "topics =  ['1 Pricing and Fairness', '2 Driver professionalism', '3 Driver behaviour', '4 Customer Service', '5 Application', '6 Lost things', '7 Vehicle Condition', '8 Safety & reliability', '9 General bad', '10 Other']\n",
    "preprocessed_examples = []\n",
    "for example in examples:\n",
    "    preprocessed_example = preprocessing(example)\n",
    "    preprocessed_examples.append(preprocessed_example)\n",
    "\n",
    "print(preprocessed_examples)\n",
    "model_predictions = new_topic_model.predict(preprocessed_examples)\n",
    "\n",
    "# Set a threshold for considering a topic present (e.g., 0.5)\n",
    "threshold = 0.3\n",
    "\n",
    "# Get the topics where the probabilities are above the threshold for each row\n",
    "predicted_topics = np.where(model_predictions >= threshold)\n",
    "\n",
    "# # Output the results\n",
    "# for i in range(predicted_topics[0].size):\n",
    "#     print(f\"Review {i+1}: {examples[i]}\")\n",
    "#     for topic_index in predicted_topics[1][predicted_topics[0] == i]:\n",
    "#         print(f\"  - Topic {topics[topic_index]}\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "print(model_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "sentiment_model = tf.keras.models.load_model(Config.SENTIMENT_MODEL_PATH)\n",
    "topic_model = tf.keras.models.load_model(Config.TOPIC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [\"really bad  driver\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "[[0.00051582]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Sentiment: ['negative']\n",
      "Predicted topic(s): ['3 Driver behaviour']\n"
     ]
    }
   ],
   "source": [
    "topics = ['1 Pricing and Fairness', '2 Driver professionalism', '3 Driver behaviour', '4 Customer Service', '5 Application', '6 Lost things', '7 Vehicle Condition', '8 Safety & reliability', '9 General bad', '10 Other']\n",
    "    \n",
    "def predict_classes(predictions):\n",
    "    predicted_labels2 = []\n",
    "    for (indx, probability) in enumerate(predictions[0]) :\n",
    "        if probability>=0.1:\n",
    "            predicted_labels2.append(indx)\n",
    "    return [topics[label] for label in predicted_labels2]        \n",
    "\n",
    "\n",
    "def get_classification(review):\n",
    "    predicted_topics = []\n",
    "    for review in review:\n",
    "        preprocessed_review = preprocessing(review)\n",
    "        sentiment = sentiment_model.predict([preprocessed_review])\n",
    "        print(sentiment)\n",
    "        if sentiment[0] <= 0.5:\n",
    "            sentiment = \"negative\"\n",
    "            # predicted_result.append(\"Sentiment: negative.\\n Predicted topic(s): \")\n",
    "            # predicted_result.append(\"negative\")\n",
    "            topic_predictions = topic_model.predict([preprocessed_review]) # in -> [] out ->[]\n",
    "            predicted_topics = predict_classes(topic_predictions)\n",
    "            # predicted_result.append(predicted_topics)\n",
    "            negative_result = f\"Sentiment: {[sentiment]}\\nPredicted topic(s): {predicted_topics}\"\n",
    "            return negative_result\n",
    "        else:\n",
    "            # predicted_result.append(\"positive\")\n",
    "            sentiment = \"positive\"\n",
    "            positive_result = f\"Sentiment: {[sentiment]}\"\n",
    "            return positive_result\n",
    "                \n",
    "\n",
    "test = get_classification(review)\n",
    "print(test)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Sentiment: ['positive']\n"
     ]
    }
   ],
   "source": [
    "class Classificator:\n",
    "    def __init__(self, config):\n",
    "        # load models\n",
    "        self.sentiment_model = tf.keras.models.load_model(config.SENTIMENT_MODEL_PATH)\n",
    "        self.topic_model = tf.keras.models.load_model(config.TOPIC_MODEL_PATH)\n",
    "        self.topics = config.TOPICS\n",
    "        \n",
    "    \n",
    "    def predict_classes(self, predictions):\n",
    "        predicted_labels2 = []\n",
    "        for (indx, probability) in enumerate(predictions[0]):\n",
    "            if probability >= 0.3:\n",
    "                predicted_labels2.append(indx)\n",
    "        return [self.topics[label] for label in predicted_labels2]        \n",
    "\n",
    "\n",
    "    def get_classification(self, review):\n",
    "        try:\n",
    "            preprocessed_review = preprocessing(review)\n",
    "            sentiment = self.sentiment_model.predict([preprocessed_review])\n",
    "            \n",
    "            if sentiment[0] <= 0.5:\n",
    "                sentiment = \"negative\"\n",
    "                topic_predictions = self.topic_model.predict([preprocessed_review]) \n",
    "                predicted_topics = self.predict_classes(topic_predictions)\n",
    "                negative_result = f\"Sentiment: {[sentiment]}\\nPredicted topic(s): {predicted_topics}\"\n",
    "                return negative_result\n",
    "            else:\n",
    "                sentiment = \"positive\"\n",
    "                positive_result = f\"Sentiment: {[sentiment]}\"\n",
    "                return positive_result                    \n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Error processing the review: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "user_review = input(\"Enter a review: \")\n",
    "classificator = Classificator(Config) \n",
    "result = classificator.get_classification(user_review)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Classificator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import nltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from nltk.sentiment.vader import SentimentIntensityAnalyzer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# nltk.download(\"vader_lexicon\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# sid = SentimentIntensityAnalyzer()\u001b[39;00m\n\u001b[0;32m      9\u001b[0m demo \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[1;32m---> 10\u001b[0m     fn\u001b[38;5;241m=\u001b[39m\u001b[43mClassificator\u001b[49m, \n\u001b[0;32m     11\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[gr\u001b[38;5;241m.\u001b[39mTextbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter a review here...\u001b[39m\u001b[38;5;124m\"\u001b[39m)], \n\u001b[0;32m     12\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[gr\u001b[38;5;241m.\u001b[39mTextbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[0;32m     13\u001b[0m     examples\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt was wonderful!\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m     15\u001b[0m demo\u001b[38;5;241m.\u001b[39mlaunch(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Classificator' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# import nltk\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# nltk.download(\"vader_lexicon\")\n",
    "# sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=Classificator, \n",
    "    inputs=[gr.Textbox(label=\"Enter a review here...\")], \n",
    "    outputs=[gr.Textbox(label=\"Topic\")],\n",
    "    examples=[[\"It was wonderful!\"]])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
