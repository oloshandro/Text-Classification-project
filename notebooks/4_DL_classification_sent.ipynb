{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Corpus Processing\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>created_at</th>\n",
       "      <th>custom_comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>01/03/2023 22:06</td>\n",
       "      <td>Great guy!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>02/03/2023 06:46</td>\n",
       "      <td>he is the best driver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>02/03/2023 14:15</td>\n",
       "      <td>The best driver!)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>02/03/2023 17:11</td>\n",
       "      <td>Perfect. Recommend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>02/03/2023 17:41</td>\n",
       "      <td>Perfect trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        created_at         custom_comment  sentiment\n",
       "0     30  01/03/2023 22:06           Great guy!!!          1\n",
       "1     33  02/03/2023 06:46  he is the best driver          1\n",
       "2     45  02/03/2023 14:15      The best driver!)          1\n",
       "3     52  02/03/2023 17:11     Perfect. Recommend          1\n",
       "4     53  02/03/2023 17:41           Perfect trip          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('../datasets/annotated_data_sentiment.csv', encoding='utf-8')\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'an', 'am' 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n",
    "             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n",
    "             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n",
    "             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n",
    "             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']\n",
    "\n",
    "short_forms = {\n",
    "    \"don't\": \"do not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"must've\": \"must have\",\n",
    "    # Add more short forms and their full forms as needed\n",
    "}\n",
    "\n",
    "def make_lower(text):\n",
    "     return text.lower()\n",
    "     \n",
    "\n",
    "def replace_short_forms(text):\n",
    "    # Create a regular expression pattern to match short forms as standalone words\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(short_forms.keys()), re.IGNORECASE)\n",
    "    \n",
    "    # Replace short forms with their corresponding full forms using a lambda function\n",
    "    full_forms_text = re.sub(pattern, lambda match: short_forms[match.group(0)], text)\n",
    "    \n",
    "    return full_forms_text\n",
    "\n",
    "\n",
    "# (?) remove quotation marks, unnecessary punctuation, [{}[]\\/+*%|^%#@!?()]\n",
    "def punctuation_remover(text):\n",
    "    pattern = r'[{}\\[\\]\\\\\\/\\+\\*%\\|\\^%#@\\(\\)\\$\\?\\!\\\"]'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "\n",
    "def lemma_stopwords_token(text):\n",
    "      le=WordNetLemmatizer()\n",
    "      word_tokens=nltk.word_tokenize(text)\n",
    "      word_tokens =[token for token in word_tokens if token.isalpha()]\n",
    "      tokens=[le.lemmatize(token) for token in word_tokens if token not in stopwords and len(token)>2]\n",
    "      processed_text =\" \".join(tokens)\n",
    "      return processed_text\n",
    "\n",
    "\n",
    "# main preprocessing function\n",
    "def preprocessing(text):\n",
    "    reviews = make_lower(text)\n",
    "    reviews = replace_short_forms(reviews)\n",
    "    reviews = punctuation_remover(reviews)\n",
    "    reviews = lemma_stopwords_token(reviews)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst driver\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"he's She's The ?? wor@@!@!st driver\"\n",
    "new_text = preprocessing(text)\n",
    "print(new_text)\n",
    "type(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great guy' 'best driver' 'best driver' ...\n",
      " 'driver cancelled trip last second then missed appointment doctor veey bad service'\n",
      " 'unprofessional and rude'\n",
      " 'inexperienced driver too quick city and doe not break turn made drive absolutely uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "data = [preprocessing(custom_comment) for custom_comment in reviews['custom_comment'].to_list()]\n",
    "# data = reviews['custom_comment'].values.tolist()\n",
    "labels = reviews['sentiment'].values.tolist()\n",
    "\n",
    "labels = [0 if label == -1 else label for label in labels]\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "embedding_dim = 50   #hyperparameter representing the dimensionality of the embedding space, in NLP tasks often set to a value between 50 and 300\n",
    "                    #each word index in the vocabulary will be represented as a 50-dimensional vector in the embedding space\n",
    "sequence_length =  100 #Keeping a fixed length of all reviews to max 400 words\n",
    "max_vocab_len = 10000  # vocabulary size limits the number of unique tokens (words or subwords)\n",
    "                    # Setting an upper limit helps control the size of the model and prevents it from learning an excessively large vocabulary.\n",
    "batch_size = 64 #Number of samples to work through before updating the internal model parameters via back propagation. The higher the batch, the more memory you need.\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "# X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4125,), (1032,), (4125,), (1032,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorizing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate text vectorization layer\n",
    "# We are using this layer to normalize, split, and map\n",
    "# strings to integers, so we set our 'output_mode' to 'int'.\n",
    "# we're using the default split function, + custom preprocessing\n",
    "\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize='lower',\n",
    "    max_tokens=max_vocab_len - 1,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# Now that the vectorize_layer has been created, call `adapt` on a text-only\n",
    "# dataset to create the vocabulary. You don't have to batch, but for very large\n",
    "# datasets this means you're not keeping spare copies of the dataset in memory.\n",
    "\n",
    "# fit the text vector to the training text\n",
    "vectorize_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a function to see the result of using this layer to preprocess some data.\n",
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label\n",
    "\n",
    "# Vectorize the data if not include in Model\n",
    "train_ds = train_dataset.map(vectorize_text)\n",
    "test_ds = test_dataset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text : \n",
      " texting while driving \n",
      "\n",
      " Vectorized format : \n",
      "[[425  66  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]] \n",
      "\n",
      " shape : (1, 100)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(X_train)\n",
    "print(f\"original text : \\n {random_sentence} \\n\\n Vectorized format : \\n{vectorize_layer([random_sentence])} \\n\\n shape : {vectorize_layer([random_sentence]).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 most common words : ['', '[UNK]', 'and', 'driver', 'not'] \n",
      " \n",
      " 5 least common words : ['abruptly', 'abrupt', 'abroad', 'ability', 'ab']\n"
     ]
    }
   ],
   "source": [
    "print(f\" 5 most common words : {vectorize_layer.get_vocabulary()[:5]} \\n \\n 5 least common words : {vectorize_layer.get_vocabulary()[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm model without PreProcessing layer\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    layers.Embedding( \n",
    "    input_dim = max_vocab_len + 1, # int, the size of our vocabulary, maximum integer index + 1 \n",
    "    output_dim = embedding_dim, # int, dimensions to which each words shall be mapped\n",
    "    input_length = sequence_length, #Length of input sequences\n",
    "    mask_zero=True #to ignore padding\n",
    "    ),\n",
    "    layers.LSTM(units=64, return_sequences=True),\n",
    "    layers.LSTM(units=32),\n",
    "    layers.Dense(units=32, activation=\"relu\"),\n",
    "    layers.Dropout(rate=0.25),\n",
    "    layers.Dense(units=1, activation=\"sigmoid\")])\n",
    "\n",
    "# compiling model\n",
    "lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #1e-3 = 0.001\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    # metrics=[tf.keras.metrics.Accuracy(),\n",
    "    #          tf.keras.metrics.FalseNegatives(),\n",
    "    metrics=[\"accuracy\"]) \n",
    "\n",
    "# Display a summary of the models structure\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_MODEL\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 100)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 50)           500050    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 64)           29440     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542995 (2.07 MB)\n",
      "Trainable params: 542995 (2.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# lstm model with PreProcessing layer\n",
    "inputs = layers.Input(shape = (1,), dtype = 'string')\n",
    "x = vectorize_layer(inputs)\n",
    "x = layers.Embedding( \n",
    "    input_dim = max_vocab_len + 1, # int, the size of our vocabulary, maximum integer index + 1 \n",
    "    output_dim = embedding_dim, # int, dimensions to which each words shall be mapped\n",
    "    input_length = sequence_length, #Length of input sequences\n",
    "    mask_zero=True #to ignore padding\n",
    "    )(x)\n",
    "x = layers.LSTM(units=64, return_sequences=True)(x)\n",
    "x = layers.LSTM(units=32)(x)\n",
    "x = layers.Dense(units=32, activation = 'relu')(x)\n",
    "x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "predictions = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "lstm_model = tf.keras.Model(inputs, predictions, name = 'LSTM_MODEL')\n",
    "lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #1e-3 = 0.001\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    # metrics=[tf.keras.metrics.Accuracy(),\n",
    "    #          tf.keras.metrics.FalseNegatives(),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:From c:\\Users\\olkos\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "65/65 [==============================] - 17s 84ms/step - loss: 0.5055 - accuracy: 0.7850\n",
      "Epoch 2/6\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.1433 - accuracy: 0.9675\n",
      "Epoch 3/6\n",
      "65/65 [==============================] - 5s 83ms/step - loss: 0.0666 - accuracy: 0.9835\n",
      "Epoch 4/6\n",
      "65/65 [==============================] - 11s 164ms/step - loss: 0.0385 - accuracy: 0.9893\n",
      "Epoch 5/6\n",
      "65/65 [==============================] - 5s 83ms/step - loss: 0.0229 - accuracy: 0.9947\n",
      "Epoch 6/6\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.0207 - accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = lstm_model.fit(X_train, y_train, #train_dataset#Training data : features (review) and classes (positive or negative)\n",
    "                    batch_size=batch_size, #Number of samples to work through before updating the internal model parameters via back propagation. The higher the batch, the more memory you need.\n",
    "                    epochs=epochs,\n",
    "                    verbose=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 6s 22ms/step - loss: 0.2768 - accuracy: 0.9428\n",
      "Test loss: 0.27682918310165405, Test accuracy: 0.942829430103302\n"
     ]
    }
   ],
   "source": [
    "results = lstm_model.evaluate(X_test, y_test)\n",
    "print ('Test loss: {0}, Test accuracy: {1}'.format(results[0],results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    WORK_DIR = 'D:/DEV2/Text-Classification-project/'\n",
    "    DATASET_SENTIMENT = WORK_DIR + '/datasets/annotated_data_sentiment.csv'\n",
    "    DATASET_TOPIC = WORK_DIR + '/datasets/annotated_data_topic_classification.csv'\n",
    "    SRC_PATH = WORK_DIR + '/src'\n",
    "    SENTIMENT_MODEL_PATH = WORK_DIR + '/models/sentiment_model'\n",
    "    TOPIC_MODEL_PATH = WORK_DIR + '/models/topic_model'\n",
    "\n",
    "# constants\n",
    "embedding_dim = 50\n",
    "sequence_length = 100 \n",
    "max_vocab_len = 10000\n",
    "batch_size = 64\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_MODEL\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_3 (TextV  (None, 100)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 100, 50)           500050    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100, 64)           29440     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542,995\n",
      "Trainable params: 542,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.5045 - accuracy: 0.7927\n",
      "Epoch 2/6\n",
      "65/65 [==============================] - 73s 1s/step - loss: 0.1466 - accuracy: 0.9661\n",
      "Epoch 3/6\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.0724 - accuracy: 0.9825\n",
      "Epoch 4/6\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.0438 - accuracy: 0.9896\n",
      "Epoch 5/6\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0268 - accuracy: 0.9935\n",
      "Epoch 6/6\n",
      "65/65 [==============================] - 70s 1s/step - loss: 0.0173 - accuracy: 0.9952\n",
      "33/33 [==============================] - 8s 127ms/step - loss: 0.2503 - accuracy: 0.9467\n",
      "Test loss: 0.2503448724746704, Test accuracy: 0.9467054009437561\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(file_path):\n",
    "    # read CSV into pandas dataframe\n",
    "    reviews = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "    # preprocess text with methods defined in preprocessing.py\n",
    "    data = [preprocessing(custom_comment) for custom_comment in reviews['custom_comment'].to_list()]\n",
    "    labels = reviews['sentiment'].values.tolist()\n",
    "    labels = [0 if label == -1 else label for label in labels]\n",
    "\n",
    "    # convert labels and data into numpy arrays\n",
    "    labels = np.array(labels)\n",
    "    data = np.array(data)\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "def build_lstm_model(max_vocab_len, embedding_dim, sequence_length):\n",
    "    # lstm model with PreProcessing layer\n",
    "    inputs = layers.Input(shape = (1,), dtype = 'string')\n",
    "    x = vectorize_layer(inputs)\n",
    "    x = layers.Embedding( \n",
    "        input_dim = max_vocab_len + 1, # int, the size of our vocabulary, maximum integer index + 1 \n",
    "        output_dim = embedding_dim, # int, dimensions to which each words shall be mapped\n",
    "        input_length = sequence_length, #Length of input sequences\n",
    "        mask_zero=True #to ignore padding\n",
    "        )(x)\n",
    "    x = layers.LSTM(units=64, return_sequences=True)(x)\n",
    "    x = layers.LSTM(units=32)(x)\n",
    "    x = layers.Dense(units=32, activation = 'relu')(x)\n",
    "    x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "    predictions = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    lstm_model = tf.keras.Model(inputs, predictions, name = 'LSTM_MODEL')\n",
    "    lstm_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #1e-3 = 0.001\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    lstm_model.summary()\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "def train_lstm_model(lstm_model, X_train, y_train, batch_size, epochs, verbose=1):\n",
    "    history = lstm_model.fit(X_train, y_train, \n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=verbose)\n",
    "    \n",
    "    results = lstm_model.evaluate(X_test, y_test)\n",
    "    print ('Test loss: {0}, Test accuracy: {1}'.format(results[0],results[1]))\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # define the path to the data\n",
    "    file_path = '../datasets/annotated_data_sentiment.csv'\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(Config.DATASET_SENTIMENT)\n",
    "\n",
    "    # Build LSTM model\n",
    "    lstm_model = build_lstm_model(max_vocab_len, embedding_dim, sequence_length)\n",
    "\n",
    "    # Train LSTM model\n",
    "    history = train_lstm_model(lstm_model, X_train, y_train, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassificationModelBuid:\n",
    "    def __init__(self, max_vocab_len, embedding_dim, sequence_length, batch_size, epochs, work_dir):\n",
    "        self.max_vocab_len = Config.max_vocab_len\n",
    "        self.embedding_dim = Config.embedding_dim\n",
    "        self.sequence_length = Config.sequence_length\n",
    "        self.batch_size = Config.batch_size\n",
    "        self.epochs = Config.epochs\n",
    "        self.work_dir = Config.WORK_DIR\n",
    "        self.dataset_sentiment = Config.DATASET_SENTIMENT\n",
    "        self.vectorize_layer = layers.TextVectorization(\n",
    "            max_tokens=max_vocab_len,\n",
    "            output_mode='int',\n",
    "            output_sequence_length=sequence_length\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_data(file_path):\n",
    "        # read CSV into pandas dataframe\n",
    "        reviews = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "        # preprocess text with methods defined in preprocessing.py\n",
    "        data = [preprocessing(custom_comment) for custom_comment in reviews['custom_comment'].to_list()]\n",
    "        labels = reviews['sentiment'].values.tolist()\n",
    "        labels = [0 if label == -1 else label for label in labels]\n",
    "\n",
    "        # convert labels and data into numpy arrays\n",
    "        labels = np.array(labels)\n",
    "        data = np.array(data)\n",
    "\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "    def build_lstm_model(max_vocab_len, embedding_dim, sequence_length):\n",
    "        # lstm model with PreProcessing layer\n",
    "        inputs = layers.Input(shape = (1,), dtype = 'string')\n",
    "        x = vectorize_layer(inputs)\n",
    "        x = layers.Embedding( \n",
    "            input_dim = max_vocab_len + 1, # int, the size of our vocabulary, maximum integer index + 1 \n",
    "            output_dim = embedding_dim, # int, dimensions to which each words shall be mapped\n",
    "            input_length = sequence_length, #Length of input sequences\n",
    "            mask_zero=True #to ignore padding\n",
    "            )(x)\n",
    "        x = layers.LSTM(units=64, return_sequences=True)(x)\n",
    "        x = layers.LSTM(units=32)(x)\n",
    "        x = layers.Dense(units=32, activation = 'relu')(x)\n",
    "        x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "        predictions = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        lstm_model = tf.keras.Model(inputs, predictions, name = 'SENTIMENT_MODEL')\n",
    "        lstm_model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #1e-3 = 0.001\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "        lstm_model.summary()\n",
    "        return lstm_model\n",
    "\n",
    "\n",
    "    def train_lstm_model(lstm_model, X_train, y_train, batch_size, epochs, verbose=1):\n",
    "        history = lstm_model.fit(X_train, y_train, \n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=verbose)\n",
    "        \n",
    "        results = lstm_model.evaluate(X_test, y_test)\n",
    "        print ('Test loss: {0}, Test accuracy: {1}'.format(results[0],results[1]))\n",
    "\n",
    "        return history\n",
    "\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        # define the path to the data\n",
    "        file_path = '../datasets/annotated_data_sentiment.csv'\n",
    "\n",
    "        # Preprocess data\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(Config.DATASET_SENTIMENT)\n",
    "\n",
    "        # Build LSTM model\n",
    "        lstm_model = build_lstm_model(max_vocab_len, embedding_dim, sequence_length)\n",
    "\n",
    "        # Train LSTM model\n",
    "        history = train_lstm_model(lstm_model, X_train, y_train, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save, load, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/DEV2/Text-Classification-project//models/sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/DEV2/Text-Classification-project//models/sentiment_model\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_model.save(Config.SENTIMENT_MODEL_PATH, 'lstm_model', save_format='tf')\n",
    "# lstm_model.save('lstm_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_MODEL\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_3 (TextV  (None, 100)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 100, 50)           500050    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100, 64)           29440     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542,995\n",
      "Trainable params: 542,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_lstm_model = tf.keras.models.load_model('lstm_model')\n",
    "\n",
    "# Show the model architecture\n",
    "new_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ride great', 'ride okay', 'ride terrible', 'smooth ride']\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9935254 ],\n",
       "       [0.96347564],\n",
       "       [0.40340927],\n",
       "       [0.9866237 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "  \"The ride was great!\",\n",
    "  \"The ride was okay.\",\n",
    "  \"the ride was terrible...\",\n",
    "  # \"driver is a scam\",\n",
    "  # \"reckless driver!\",\n",
    "  # \"it took longer time, but the driver was good\",\n",
    "  # \"vehicle of premium class\",\n",
    "  # \"Great experience.I'd recommend this service to my friends.\",\n",
    "  # \"The driver swore and racist!\",\n",
    "  # \"The drivers behaviour is inappropriate\",\n",
    "  \"smooth ride\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "preprocessed_examples = []\n",
    "for example in examples:\n",
    "    preprocessed_example = preprocessing(example)\n",
    "    preprocessed_examples.append(preprocessed_example)\n",
    "\n",
    "print(preprocessed_examples)\n",
    "new_lstm_model.predict(preprocessed_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessing import preprocessing\n",
    "\n",
    "def preprocess_new_data(new_data):\n",
    "    preprocessed_data = [preprocessing(custom_comment) for custom_comment in new_data]\n",
    "    return preprocessed_data\n",
    "\n",
    "\n",
    "def predict_on_new_data(lstm_model, preprocessed_data):\n",
    "    # Make predictions\n",
    "    predictions = lstm_model.predict(preprocessed_data)\n",
    "    if predictions[0] <= 0.5:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"positive\"\n",
    "    return f\"Sentiment: {sentiment}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # load the model\n",
    "    lstm_model = tf.keras.models.load_model('lstm_model')\n",
    "    \n",
    "    # new_data = input(\"Please, insert you review: ... \")\n",
    "    new_data = [\"reckless driver!\",\n",
    "                \"\"\"The drivers behaviour is inappropriate\"\"\",\n",
    "                \"\"\"I had a couple of rides with your service before and they were nice, but this time there wasn't a seatbelt which I believe is totally not OK. and the driver just said Are yoou going or not??\"\"\",\n",
    "                \"\"\"The driver swore and racist!\"\"\",\n",
    "                \"\"\"Nice driver, really helpful\"\"\",\n",
    "                \"\"\"vehicle of premium class\"\"\",\n",
    "                \"\"\"Great experience.I'd recommend this service to my friends.\"\"\",\n",
    "                \"\"\"smooth ride\"\"\",\n",
    "                \"\"\"it took longer time, but the driver was good\"\"\"]\n",
    "\n",
    "    # preprocess new data\n",
    "    preprocessed_new_data = preprocess_new_data(new_data)\n",
    "\n",
    "    # Make predictions on new data\n",
    "    predictions = predict_on_new_data(lstm_model, preprocessed_new_data)\n",
    "    print (predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
